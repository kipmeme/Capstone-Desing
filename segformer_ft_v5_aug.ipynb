{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0494adde-88aa-44e3-844d-7ee7473072ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 06:14:58.865482: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-13 06:14:58.868933: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-13 06:14:58.876708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-13 06:14:58.889658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-13 06:14:58.893434: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-13 06:14:58.903290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-13 06:14:59.680026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f7ffef-3e02-4db8-a294-fcab7d9e8148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in building-defects-4 to png-mask-semantic:: 100%|██████████| 24278/24278 [00:02<00:00, 10632.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to building-defects-4 in png-mask-semantic:: 100%|██████████| 330/330 [00:00<00:00, 5289.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"rWhzxDa8oLFF7F6zw3cG\")\n",
    "project = rf.workspace(\"cd-pq7yy\").project(\"building-defects-xpjmz\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"png-mask-semantic\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9932e470-0540-40cd-bef0-c8107c82257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, feature_extractor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory of the dataset containing the images + annotations.\n",
    "            feature_extractor (SegFormerFeatureExtractor): feature extractor to prepare images + segmentation maps.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # Load class mapping from CSV file (e.g., _classes.csv)\n",
    "        self.classes_csv_file = os.path.join(self.root_dir, \"_classes.csv\")\n",
    "        with open(self.classes_csv_file, 'r') as fid:\n",
    "            data = [l.split(',') for i, l in enumerate(fid) if i != 0]\n",
    "        self.id2label = {x[0]: x[1] for x in data}\n",
    "        \n",
    "        image_file_names = [f for f in os.listdir(self.root_dir) if '.jpg' in f]\n",
    "        mask_file_names = [f for f in os.listdir(self.root_dir) if '.png' in f]\n",
    "        \n",
    "        self.images = sorted(image_file_names)\n",
    "        self.masks = sorted(mask_file_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.root_dir, self.images[idx]))\n",
    "        segmentation_map = Image.open(os.path.join(self.root_dir, self.masks[idx]))\n",
    "\n",
    "        # Convert segmentation map to numpy array (without ignoring any labels)\n",
    "        segmentation_map = np.array(segmentation_map)\n",
    "\n",
    "        # Apply feature extractor to both image and segmentation map\n",
    "        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n",
    "\n",
    "        # Remove batch dimension\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_()\n",
    "\n",
    "        return encoded_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01212c90-e8fe-46c5-ab32-66b6f065281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        \n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        \n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\", \n",
    "            return_dict=False, \n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "        \n",
    "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
    "        \n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return(outputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes, \n",
    "                ignore_index=255, \n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            \n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            \n",
    "            for k,v in metrics.items():\n",
    "                self.log(k,v)\n",
    "            \n",
    "            return(metrics)\n",
    "        else:\n",
    "            return({'loss': loss})\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        \n",
    "        return({'val_loss': loss})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "              num_labels=self.num_classes, \n",
    "              ignore_index=255, \n",
    "              reduce_labels=False,\n",
    "          )\n",
    "        \n",
    "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        \n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\":val_mean_iou, \"val_mean_accuracy\":val_mean_accuracy}\n",
    "        for k,v in metrics.items():\n",
    "            self.log(k,v)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        self.test_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "            \n",
    "        return({'test_loss': loss})\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        metrics = self.test_mean_iou.compute(\n",
    "              num_labels=self.num_classes, \n",
    "              ignore_index=255, \n",
    "              reduce_labels=False,\n",
    "          )\n",
    "       \n",
    "        avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        test_mean_iou = metrics[\"mean_iou\"]\n",
    "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "        metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\":test_mean_iou, \"test_mean_accuracy\":test_mean_accuracy}\n",
    "        \n",
    "        for k,v in metrics.items():\n",
    "            self.log(k,v)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e113f112-960d-496c-885d-a51b7098f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# IoU 계산 함수\n",
    "def compute_iou(predictions, targets, num_classes):\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = predictions == cls\n",
    "        target_inds = targets == cls\n",
    "        intersection = torch.sum(pred_inds & target_inds)\n",
    "        union = torch.sum(pred_inds | target_inds)\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # NaN 대신 다른 값으로 처리 가능\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(union))\n",
    "    return torch.tensor(ious).nanmean()  # NaN을 제외한 평균 IoU 계산\n",
    "\n",
    "# SegFormer fine-tuning 클래스\n",
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        \n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "        \n",
    "        # Pretrained SegFormer 모델 로드\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\",\n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        # Logits upsampling to match mask size\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        # IoU 계산\n",
    "        mean_iou = compute_iou(predicted, masks, self.num_classes)\n",
    "        \n",
    "        metrics = {'loss': loss, 'mean_iou': mean_iou}\n",
    "        \n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "            for k, v in metrics.items():\n",
    "                self.log(k, v)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        # Logits upsampling to match mask size\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        # IoU 계산\n",
    "        mean_iou = compute_iou(predicted, masks, self.num_classes)\n",
    "        \n",
    "        return {'val_loss': loss, 'val_mean_iou': mean_iou}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_val_mean_iou = torch.stack([x[\"val_mean_iou\"] for x in outputs]).mean()\n",
    "\n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\": avg_val_mean_iou}\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        # Logits upsampling to match mask size\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        # IoU 계산\n",
    "        mean_iou = compute_iou(predicted, masks, self.num_classes)\n",
    "        \n",
    "        return {'test_loss': loss, 'test_mean_iou': mean_iou}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        avg_test_mean_iou = torch.stack([x[\"test_mean_iou\"] for x in outputs]).mean()\n",
    "\n",
    "        metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\": avg_test_mean_iou}\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac11ea24-1349-4b12-8c5a-e6357f04f4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "The following named arguments are not valid for `SegformerFeatureExtractor.__init__` and were ignored: 'feature_extractor_type'\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b5-finetuned-cityscapes-1024-1024 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([19, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([19]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\")\n",
    "feature_extractor.do_reduce_labels = False\n",
    "feature_extractor.size = 512\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(f\"{dataset.location}/train/\", feature_extractor)\n",
    "val_dataset = SemanticSegmentationDataset(f\"{dataset.location}/valid/\", feature_extractor)\n",
    "test_dataset = SemanticSegmentationDataset(f\"{dataset.location}/test/\", feature_extractor)\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 0\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "segformer_finetuner = SegformerFinetuner(\n",
    "    train_dataset.id2label, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=val_dataloader, \n",
    "    test_dataloader=test_dataloader, \n",
    "    metrics_interval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d52402f-0825-4108-bc39-19f1b191efd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type                             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model | SegformerForSemanticSegmentation | 84.6 M\n",
      "-----------------------------------------------------------\n",
      "84.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "84.6 M    Total params\n",
      "338.389   Total estimated model params size (MB)\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|█████████▏| 36/39 [00:21<00:01,  1.67it/s, loss=1.2, v_num=20] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 38/39 [00:21<00:00,  1.74it/s, loss=1.2, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.08it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 39/39 [00:22<00:00,  1.76it/s, loss=1.2, v_num=20]\n",
      "Epoch 1:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.832, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 38/39 [00:21<00:00,  1.79it/s, loss=0.832, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.13it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.832, v_num=20]\n",
      "Epoch 2:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.61, v_num=20] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.61, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.99it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 39/39 [00:21<00:00,  1.83it/s, loss=0.61, v_num=20]\n",
      "Epoch 3:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.466, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.466, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.466, v_num=20]\n",
      "Epoch 4:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.38, v_num=20] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.38, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.69it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.38, v_num=20]\n",
      "Epoch 5:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.355, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.355, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.22it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.355, v_num=20]\n",
      "Epoch 6:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.319, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.319, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.79it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.319, v_num=20]\n",
      "Epoch 7:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.273, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 38/39 [00:21<00:00,  1.79it/s, loss=0.273, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.77it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.273, v_num=20]\n",
      "Epoch 8:  92%|█████████▏| 36/39 [00:21<00:01,  1.71it/s, loss=0.252, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 38/39 [00:21<00:00,  1.78it/s, loss=0.252, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.91it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 39/39 [00:21<00:00,  1.79it/s, loss=0.252, v_num=20]\n",
      "Epoch 9:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.223, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.223, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.09it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.223, v_num=20]\n",
      "Epoch 10:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.204, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.204, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.03it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 39/39 [00:21<00:00,  1.83it/s, loss=0.204, v_num=20]\n",
      "Epoch 11:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.188, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.188, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.25it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.188, v_num=20]\n",
      "Epoch 12:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.192, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.192, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.12it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.192, v_num=20]\n",
      "Epoch 13:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.181, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.181, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.181, v_num=20]\n",
      "Epoch 14:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.166, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.166, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.12it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.166, v_num=20]\n",
      "Epoch 15:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.156, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.156, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.80it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.156, v_num=20]\n",
      "Epoch 16:  92%|█████████▏| 36/39 [00:21<00:01,  1.71it/s, loss=0.139, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  97%|█████████▋| 38/39 [00:21<00:00,  1.78it/s, loss=0.139, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.89it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 39/39 [00:21<00:00,  1.80it/s, loss=0.139, v_num=20]\n",
      "Epoch 17:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.149, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 38/39 [00:21<00:00,  1.78it/s, loss=0.149, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.86it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 39/39 [00:21<00:00,  1.80it/s, loss=0.149, v_num=20]\n",
      "Epoch 18:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.142, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.142, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.48it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.142, v_num=20]\n",
      "Epoch 19:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.123, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  97%|█████████▋| 38/39 [00:21<00:00,  1.79it/s, loss=0.123, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.67it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 39/39 [00:21<00:00,  1.80it/s, loss=0.123, v_num=20]\n",
      "Epoch 20:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.123, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  97%|█████████▋| 38/39 [00:21<00:00,  1.79it/s, loss=0.123, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.123, v_num=20]\n",
      "Epoch 21:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.126, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.126, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.90it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.126, v_num=20]\n",
      "Epoch 22:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.122, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.122, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.21it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.122, v_num=20]\n",
      "Epoch 23:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.111, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.111, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.62it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.111, v_num=20]\n",
      "Epoch 24:  92%|█████████▏| 36/39 [00:20<00:01,  1.72it/s, loss=0.111, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 38/39 [00:21<00:00,  1.79it/s, loss=0.111, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.81it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 39/39 [00:21<00:00,  1.80it/s, loss=0.111, v_num=20]\n",
      "Epoch 25:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.107, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 38/39 [00:20<00:00,  1.81it/s, loss=0.107, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.03it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.107, v_num=20]\n",
      "Epoch 26:  92%|█████████▏| 36/39 [00:20<00:01,  1.74it/s, loss=0.099, v_num=20] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 38/39 [00:21<00:00,  1.81it/s, loss=0.099, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.90it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.099, v_num=20]\n",
      "Epoch 27:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.0955, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.0955, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  4.06it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 39/39 [00:21<00:00,  1.82it/s, loss=0.0955, v_num=20]\n",
      "Epoch 28:  92%|█████████▏| 36/39 [00:20<00:01,  1.73it/s, loss=0.111, v_num=20] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 38/39 [00:21<00:00,  1.80it/s, loss=0.111, v_num=20]\n",
      "Validating:  67%|██████▋   | 2/3 [00:00<00:00,  3.89it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.111, v_num=20]\n",
      "Epoch 28: 100%|██████████| 39/39 [00:21<00:00,  1.81it/s, loss=0.111, v_num=20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    min_delta=0.00, \n",
    "    patience=100, \n",
    "    verbose=False, \n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=[1], \n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    max_epochs=500,\n",
    "    val_check_interval=len(train_dataloader),\n",
    ")\n",
    "trainer.fit(segformer_finetuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425d6640-0759-43b9-9ed7-fa72a292f356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1674), started 5 days, 23:57:23 ago. (Use '!kill 1674' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e9e9185e5b88b2e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e9e9185e5b88b2e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f965fb9-3339-4ce0-ba15-fc5786f7a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU: 0.6066502191226778\n",
      "Class 0: Precision=0.9782882381460749, Recall=0.9209690529533882, F1-score=0.9478245708023714\n",
      "Class 1: Precision=0.8128220263341247, Recall=0.971746149654169, F1-score=0.8695058867608355\n",
      "Class 2: Precision=0.256244630742823, Recall=0.22283234672908223, F1-score=0.21923270363762812\n",
      "Overall Accuracy: 0.8720684051513672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# IoU 계산 함수\n",
    "def compute_iou(predictions, targets, num_classes):\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = predictions == cls\n",
    "        target_inds = targets == cls\n",
    "        intersection = np.sum(pred_inds & target_inds)\n",
    "        union = np.sum(pred_inds | target_inds)\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # NaN 대신 처리할 값을 넣을 수 있음\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(union))\n",
    "    return np.nanmean(ious)  # NaN을 제외한 평균 IoU\n",
    "\n",
    "# 클래스별로 정밀도, 재현율, F1-score, 정확도 계산 함수\n",
    "def compute_classwise_metrics(predictions, targets, num_classes):\n",
    "    precision = precision_score(targets.flatten(), predictions.flatten(), average=None, labels=range(num_classes))\n",
    "    recall = recall_score(targets.flatten(), predictions.flatten(), average=None, labels=range(num_classes))\n",
    "    f1 = f1_score(targets.flatten(), predictions.flatten(), average=None, labels=range(num_classes))\n",
    "    accuracy = accuracy_score(targets.flatten(), predictions.flatten())\n",
    "    \n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "# 모델 추론 및 성능 지표 계산 함수\n",
    "def evaluate_model_on_test_data(dataloader, model, num_classes):\n",
    "    iou_list = []\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=images)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted_mask = upsampled_logits.argmax(dim=1).cpu().numpy()\n",
    "        masks = masks.cpu().numpy()\n",
    "\n",
    "        # IoU 계산\n",
    "        iou = compute_iou(predicted_mask, masks, num_classes)\n",
    "        iou_list.append(iou)\n",
    "\n",
    "        # 정밀도, 재현율, F1-score 계산\n",
    "        precision, recall, f1, accuracy = compute_classwise_metrics(predicted_mask, masks, num_classes)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    avg_iou = np.mean(iou_list)\n",
    "    avg_precision = np.mean(precision_list, axis=0)\n",
    "    avg_recall = np.mean(recall_list, axis=0)\n",
    "    avg_f1 = np.mean(f1_list, axis=0)\n",
    "\n",
    "    return avg_iou, avg_precision, avg_recall, avg_f1, accuracy\n",
    "\n",
    "# 모델 성능 평가\n",
    "num_classes = 3  # 클래스 개수\n",
    "avg_iou, avg_precision, avg_recall, avg_f1, accuracy = evaluate_model_on_test_data(test_dataloader, segformer_finetuner.model, num_classes)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Average IoU: {avg_iou}\")\n",
    "for cls in range(num_classes):\n",
    "    print(f\"Class {cls}: Precision={avg_precision[cls]}, Recall={avg_recall[cls]}, F1-score={avg_f1[cls]}\")\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea3e9b-34ca-4d08-a682-2d9eed686cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ee613-834a-4f9c-bbf1-832e6abf9547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e3590-3267-4c28-9515-f57a49788ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be28e6c4-9959-4832-b715-3473e8a1a74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8daa31-1b9f-4b49-8a5e-153c6c575344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b685ff-d6ef-4843-9843-a000d6551ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
